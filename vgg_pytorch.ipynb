{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2d0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79358f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = get_default_device()\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-3\n",
    "NUM_CLASSES = 10\n",
    "NUM_EPOCHS = 20\n",
    "CLASSES = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(\n",
    "    data_dir,\n",
    "    batch_size,\n",
    "    image_size=(224, 224),\n",
    "    random_seed=47,\n",
    "    valid_size=0.1,\n",
    "    shuffle=True,\n",
    "    test=False,\n",
    "    download=True,\n",
    "):\n",
    "    data_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if test:\n",
    "        dataset = datasets.CIFAR10(\n",
    "            root=data_dir, train=False, transform=data_transforms, download=download\n",
    "        )\n",
    "\n",
    "        data_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "        )\n",
    "\n",
    "        return data_loader\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True, transform=data_transforms, download=download\n",
    "    )\n",
    "\n",
    "    valid_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True, transform=data_transforms, download=download\n",
    "    )\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_indices, valid_indices = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(indices=train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(indices=valid_indices)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_dataset, batch_size=batch_size, sampler=train_sampler\n",
    "    )\n",
    "\n",
    "    valid_dataloader = DataLoader(\n",
    "        dataset=valid_dataset, batch_size=batch_size, sampler=valid_sampler\n",
    "    )\n",
    "\n",
    "    return (train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader = data_loader(\n",
    "    data_dir=\"./data\",\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_dataloader = data_loader(\n",
    "    data_dir=\"./data\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    test=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ccade",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # this has been written as per the source code from pytorch\n",
    "\n",
    "# class VGG(nn.Module):\n",
    "#     def __init__(self, cfgs, num_classes=1000):\n",
    "#         super(VGG, self).__init__()\n",
    "#         self.features = self.make_layers(cfgs)\n",
    "#         self.num_classes = num_classes\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d(output_size=(7, 7))\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(in_features=7 * 7 * 512, out_features=4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             nn.Linear(in_features=4096, out_features=4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             nn.Linear(in_features=4096, out_features=self.num_classes),\n",
    "#         )\n",
    "\n",
    "#     def make_layers(self, cfg, batch_norm=False):\n",
    "#         layers = []\n",
    "#         in_channels = 3\n",
    "#         for conf in cfg:\n",
    "#             if conf == \"M\":\n",
    "#                 layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "#             else:\n",
    "#                 conv2d = nn.Conv2d(\n",
    "#                     in_channels=in_channels,\n",
    "#                     out_channels=conf,\n",
    "#                     kernel_size=3,\n",
    "#                     padding=1,\n",
    "#                     stride=1,\n",
    "#                 )\n",
    "#                 if batch_norm:\n",
    "#                     layers += [\n",
    "#                         conv2d,\n",
    "#                         nn.BatchNorm2d(num_features=conf),\n",
    "#                         nn.ReLU(inplace=True),\n",
    "#                     ]\n",
    "#                 else:\n",
    "#                     layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "#                 in_channels = conf\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = torch.flatten(input=x, start_dim=1)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "    \n",
    "# model_confs = {\n",
    "#     'VGG16_url': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "#     'VGG16_confs': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "# }\n",
    "\n",
    "# model = VGG(cfgs=model_confs['VGG16_confs']).to(DEVICE)\n",
    "# print(model)\n",
    "# model_state_dict = load_state_dict_from_url(url=model_confs['VGG16_url'], progress=True)\n",
    "# model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3b0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad547302",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_model = model\n",
    "last_layer_in_features = fine_tune_model.classifier[6].in_features\n",
    "fine_tune_model.classifier[6] = nn.Linear(in_features=last_layer_in_features, out_features=NUM_CLASSES)\n",
    "fine_tune_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0efab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "fine_tune_optimizer = torch.optim.SGD(\n",
    "    fine_tune_model.parameters(), lr=LEARNING_RATE, weight_decay=5e-3, momentum=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca35ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(num_epochs, model, criterion, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        for idx, (images, labels) in enumerate(tqdm(train_dataloader)):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs} | Loss: {loss.item()}\")\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            print('\\nPerforming Validation...\\n')\n",
    "            for images, labels in tqdm(valid_dataloader):\n",
    "                images = images.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                del images, labels, outputs\n",
    "            print(f\"Validation Accuracy: {(correct/total)*100}\")\n",
    "            print(\"%\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf4833a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is pretraining i.e. training entire model from scratch but with pretrained weights\n",
    "\n",
    "fit_model(\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    model=fine_tune_model,\n",
    "    criterion=loss_fn,\n",
    "    optimizer=fine_tune_optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110e9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction_model = model\n",
    "last_layer_in_features = feature_extraction_model.classifier[6].in_features\n",
    "feature_extraction_model.classifier[6] = nn.Linear(in_features=last_layer_in_features, out_features=NUM_CLASSES)\n",
    "feature_extraction_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79120aef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "for name, parameter in feature_extraction_model.named_parameters():\n",
    "    if parameter.requires_grad:\n",
    "        params_to_update.append(parameter)\n",
    "        print(name)\n",
    "print()\n",
    "print(params_to_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "feature_extraction_optimizer = torch.optim.SGD(\n",
    "   params_to_update, lr=LEARNING_RATE, weight_decay=5e-3, momentum=0.9 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ce72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is feature extraction i.e. training last layer of the model keeping pretrained weights as it is\n",
    "\n",
    "fit_model(\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    model=feature_extraction_model,\n",
    "    criterion=loss_fn,\n",
    "    optimizer=feature_extraction_optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, criterion, optimizer):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(test_dataloader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "        print(f\"Testing Accuracy: {(correct/total)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e2c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(\n",
    "    model=feature_extraction_model,\n",
    "    criterion=loss_fn,\n",
    "    optimizer=feature_extraction_optimizer,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
